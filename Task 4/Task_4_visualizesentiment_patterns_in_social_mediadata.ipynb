{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hatimloha/Prodigy_InfoTech/blob/main/Task_4_visualizesentiment_patterns_in_social_mediadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzeand visualizesentiment patterns in social mediadata to understand public opinionand attitudes towards specific topicsor brands. This task involves naturallanguage processing (NLP)techniques to extract sentiment fromtextual data.​​"
      ],
      "metadata": {
        "id": "owPjv2V_fv3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpMHsoD_BYq8"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "data = pd.read_csv('/content/twitter_training.csv')"
      ],
      "metadata": {
        "id": "Q-Ut1bUiBcCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# head used to fetch top 5 row and column\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ONC4zPAcBeK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# head used to fetch last 5 row and column\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "biCKg_snGSJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the 'twitter_training.csv' file into a DataFrame with specified column names: 'ID', 'Entity', 'Sentiment', and 'Content'.\n",
        "col_names = ['ID', 'Entity', 'Sentiment', 'Content']\n",
        "df = pd.read_csv('twitter_training.csv', names=col_names)"
      ],
      "metadata": {
        "id": "n7ACxmh0BjOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows of the DataFrame to get a quick overview of the data.\n",
        "df.head()"
      ],
      "metadata": {
        "id": "G0NuuNU1BlH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the dimensions of the DataFrame as a tuple (number of rows, number of columns).\n",
        "df.shape"
      ],
      "metadata": {
        "id": "mt5GxGHdBqo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate descriptive statistics for all columns in the DataFrame, including both numeric and non-numeric data.\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "lt6IhX_ABsrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "pYvVeSl-Gdsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of missing (null) values in each column of the DataFrame.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "VvoT8uuKBv3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=0 , inplace=True) #drop null values"
      ],
      "metadata": {
        "id": "YuZ5XvBlBzG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify if any missing (null) values remain in the DataFrame after dropping rows with null values.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "tppRHTCIB1Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of duplicate rows in the DataFrame.\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "Rz_vxWUTB3G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all duplicate rows from the DataFrame and apply the change in place, then verify if any duplicates remain.\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "lU1yH79YB5aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the dimensions of the DataFrame to check the number of rows and columns after dropping null and duplicate values.\n",
        "df.shape"
      ],
      "metadata": {
        "id": "wWoz8XpvB7Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each unique sentiment value in the 'Sentiment' column and store the results in sentiment_counts.\n",
        "sentiment_counts = df['Sentiment'].value_counts()\n",
        "sentiment_counts"
      ],
      "metadata": {
        "id": "8MIlkQ4IB90t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot to visualize the distribution of sentiments, specifying figure size, colors, and axis labels.\n",
        "plt.figure(figsize=(6, 3))\n",
        "sentiment_counts.plot(kind='bar', color=['red', 'green', 'yellow', 'blue'])\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yD4NUO_wCATl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis On particular brand or company"
      ],
      "metadata": {
        "id": "MSCXmacxD-9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame for rows containing 'Microsoft' in the 'Entity' column, then count the occurrences of each sentiment value in the filtered data.\n",
        "brand_data = df[df['Entity'].str.contains('Microsoft', case=False)]\n",
        "brand_sentiment_counts = brand_data['Sentiment'].value_counts()\n",
        "brand_sentiment_counts"
      ],
      "metadata": {
        "id": "KKyYQ85MCDD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pie chart to visualize the sentiment distribution for the entity 'Microsoft', displaying percentages and setting the start angle.\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(brand_sentiment_counts, labels=brand_sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Sentiment Distribution for Microsoft')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OZWKokAaCFz4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
